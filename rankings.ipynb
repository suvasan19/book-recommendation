{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rankings.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZAUr8lBhF0oMzbdZ8JGrM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PThBmrjehqR",
        "outputId": "f156a1f7-1e9a-46ff-a947-7d608e2fa80e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_precision([0,1,0,0,1,0,1,0,0,0])\n",
            "0.44285714285714284\n",
            "average_precision([1,0,1,0,0,1,0,0,1,1])\n",
            "0.6222222222222221\n",
            "mean_average_precision([[1,0,1,0,0,1,0,0,1,1],[0,1,0,0,1,0,1,0,0,0]])\n",
            "0.5325396825396824\n",
            "dcg_at_k([1.0,0.6,0.0,0.8,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0],3)\n",
            "1.6\n",
            "ndcg_at_k([1.0,0.6,0.0,0.8,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0],3)\n",
            "0.638787886479598\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Information Retrieval metrics\n",
        "\n",
        "Useful Resources:\n",
        "http://www.cs.utexas.edu/~mooney/ir-course/slides/Evaluation.ppt\n",
        "http://www.nii.ac.jp/TechReports/05-014E.pdf\n",
        "http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
        "http://hal.archives-ouvertes.fr/docs/00/72/67/60/PDF/07-busa-fekete.pdf\n",
        "Learning to Rank for Information Retrieval (Tie-Yan Liu)\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "def mean_reciprocal_rank(rs):\n",
        "    \"\"\"Score is reciprocal of the rank of the first relevant item\n",
        "\n",
        "    First element is 'rank 1'.  Relevance is binary (nonzero is relevant).\n",
        "\n",
        "    Example from http://en.wikipedia.org/wiki/Mean_reciprocal_rank\n",
        "    >>> rs = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
        "    >>> mean_reciprocal_rank(rs)\n",
        "    0.61111111111111105\n",
        "    >>> rs = np.array([[0, 0, 0], [0, 1, 0], [1, 0, 0]])\n",
        "    >>> mean_reciprocal_rank(rs)\n",
        "    0.5\n",
        "    >>> rs = [[0, 0, 0, 1], [1, 0, 0], [1, 0, 0]]\n",
        "    >>> mean_reciprocal_rank(rs)\n",
        "    0.75\n",
        "\n",
        "    Args:\n",
        "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "\n",
        "    Returns:\n",
        "        Mean reciprocal rank\n",
        "    \"\"\"\n",
        "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
        "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
        "\n",
        "def r_precision(r):\n",
        "    \"\"\"Score is precision at R where R is the number of relevant documents for a query.\n",
        "\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "\n",
        "    >>> r = [0, 0, 1]\n",
        "    >>> r_precision(r)\n",
        "    0.0\n",
        "    >>> r = [0, 1, 0]\n",
        "    >>> r_precision(r)\n",
        "    0.0\n",
        "    >>> r = [1, 0, 0]\n",
        "    >>> r_precision(r)\n",
        "    1.0\n",
        "\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "\n",
        "    Returns:\n",
        "        R Precision\n",
        "    \"\"\"\n",
        "    r = np.asarray(r) != 0\n",
        "    z = r.nonzero()[0]\n",
        "    if not z.size:\n",
        "        return 0.\n",
        "    return np.mean(r[:len(z)])\n",
        "\n",
        "def r_precision_incorrect(r):\n",
        "    \"\"\"Score is precision after all relevant documents have been retrieved\n",
        "\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "\n",
        "    >>> r = [0, 0, 1]\n",
        "    >>> r_precision(r)\n",
        "    0.33333333333333331\n",
        "    >>> r = [0, 1, 0]\n",
        "    >>> r_precision(r)\n",
        "    0.5\n",
        "    >>> r = [1, 0, 0]\n",
        "    >>> r_precision(r)\n",
        "    1.0\n",
        "\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "\n",
        "    Returns:\n",
        "        R Precision\n",
        "    \"\"\"\n",
        "    r = np.asarray(r) != 0\n",
        "    z = r.nonzero()[0]\n",
        "    if not z.size:\n",
        "        return 0.\n",
        "    return np.mean(r[:z[-1] + 1])\n",
        "\n",
        "def precision_at_k(r, k):\n",
        "    \"\"\"Score is precision @ k\n",
        "\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "\n",
        "    >>> r = [0, 0, 1]\n",
        "    >>> precision_at_k(r, 1)\n",
        "    0.0\n",
        "    >>> precision_at_k(r, 2)\n",
        "    0.0\n",
        "    >>> precision_at_k(r, 3)\n",
        "    0.33333333333333331\n",
        "    >>> precision_at_k(r, 4)\n",
        "    Traceback (most recent call last):\n",
        "        File \"<stdin>\", line 1, in ?\n",
        "    ValueError: Relevance score length < k\n",
        "\n",
        "\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "\n",
        "    Returns:\n",
        "        Precision @ k\n",
        "\n",
        "    Raises:\n",
        "        ValueError: len(r) must be >= k\n",
        "    \"\"\"\n",
        "    assert k >= 1\n",
        "    r = np.asarray(r)[:k] != 0\n",
        "    if r.size != k:\n",
        "        raise ValueError('Relevance score length < k')\n",
        "    return np.mean(r)\n",
        "\n",
        "def average_precision(r):\n",
        "    \"\"\"Score is average precision (area under PR curve)\n",
        "\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "\n",
        "    >>> r = [1, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
        "    >>> delta_r = 1. / sum(r)\n",
        "    >>> sum([sum(r[:x + 1]) / (x + 1.) * delta_r for x, y in enumerate(r) if y])\n",
        "    0.7833333333333333\n",
        "    >>> average_precision(r)\n",
        "    0.78333333333333333\n",
        "\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "\n",
        "    Returns:\n",
        "        Average precision\n",
        "    \"\"\"\n",
        "    r = np.asarray(r) != 0\n",
        "    out = [precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n",
        "    if not out:\n",
        "        return 0.\n",
        "    return np.mean(out)\n",
        "\n",
        "\n",
        "def mean_average_precision(rs):\n",
        "    \"\"\"Score is mean average precision\n",
        "\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "\n",
        "    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1]]\n",
        "    >>> mean_average_precision(rs)\n",
        "    0.78333333333333333\n",
        "    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [0]]\n",
        "    >>> mean_average_precision(rs)\n",
        "    0.39166666666666666\n",
        "\n",
        "    Args:\n",
        "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "\n",
        "    Returns:\n",
        "        Mean average precision\n",
        "    \"\"\"\n",
        "    return np.mean([average_precision(r) for r in rs])\n",
        "\n",
        "def dcg_at_k(r, k, method=0):\n",
        "    \"\"\"Score is discounted cumulative gain (dcg)\n",
        "\n",
        "    Relevance is positive real values.  Can use binary\n",
        "    as the previous methods.\n",
        "\n",
        "    Example from\n",
        "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
        "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
        "    >>> dcg_at_k(r, 1)\n",
        "    3.0\n",
        "    >>> dcg_at_k(r, 1, method=1)\n",
        "    3.0\n",
        "    >>> dcg_at_k(r, 2)\n",
        "    5.0\n",
        "    >>> dcg_at_k(r, 2, method=1)\n",
        "    4.2618595071429155\n",
        "    >>> dcg_at_k(r, 10)\n",
        "    9.6051177391888114\n",
        "    >>> dcg_at_k(r, 11)\n",
        "    9.6051177391888114\n",
        "\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "        k: Number of results to consider\n",
        "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
        "\n",
        "    Returns:\n",
        "        Discounted cumulative gain\n",
        "    \"\"\"\n",
        "    r = np.asfarray(r)[:k]\n",
        "    if r.size:\n",
        "        return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
        "    return 0.\n",
        "\n",
        "def ndcg_at_k(r, k, method=0):\n",
        "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
        "\n",
        "    Relevance is positive real values.  Can use binary\n",
        "    as the previous methods.\n",
        "\n",
        "    Example from\n",
        "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
        "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
        "    >>> ndcg_at_k(r, 1)\n",
        "    1.0\n",
        "    >>> r = [2, 1, 2, 0]\n",
        "    >>> ndcg_at_k(r, 4)\n",
        "    0.9203032077642922\n",
        "    >>> ndcg_at_k(r, 4, method=1)\n",
        "    0.96519546960144276\n",
        "    >>> ndcg_at_k([0], 1)\n",
        "    0.0\n",
        "    >>> ndcg_at_k([1], 2)\n",
        "    1.0\n",
        "\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "        k: Number of results to consider\n",
        "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
        "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
        "\n",
        "    Returns:\n",
        "        Normalized discounted cumulative gain\n",
        "    \"\"\"\n",
        "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
        "    if not dcg_max:\n",
        "        return 0.\n",
        "    return dcg_at_k(r, k, method) / dcg_max\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #import doctest\n",
        "    #doctest.testmod()\n",
        "    print(\"average_precision([0,1,0,0,1,0,1,0,0,0])\")\n",
        "    print(average_precision([0,1,0,0,1,0,1,0,0,0]))\n",
        "    print(\"average_precision([1,0,1,0,0,1,0,0,1,1])\")\n",
        "    print(average_precision([1,0,1,0,0,1,0,0,1,1]))\n",
        "    print(\"mean_average_precision([[1,0,1,0,0,1,0,0,1,1],[0,1,0,0,1,0,1,0,0,0]])\")\n",
        "    print(mean_average_precision([[1,0,1,0,0,1,0,0,1,1],[0,1,0,0,1,0,1,0,0,0]]))\n",
        "    print(\"dcg_at_k([1.0,0.6,0.0,0.8,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0],3)\")\n",
        "    print(dcg_at_k([1.0,0.6,0.0,0.8,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0],3))\n",
        "    print(\"ndcg_at_k([1.0,0.6,0.0,0.8,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0],3)\")\n",
        "    print(ndcg_at_k([1.0,0.6,0.0,0.8,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0],3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jaccard_ranks = [[1,0,0,0,0,0,0,0,0,0],\n",
        "[1,0,0,0,0,0,0,0,0,0],\n",
        "[1,0,0,0,0,0,0,0,0,0],\n",
        "[1,0,0,0,0,0,0,0,0,0],\n",
        "[1,0,0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,1,0,0,1],\n",
        "[0,0,0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0,0,0],\n",
        "[0,1,0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0,0,1],\n",
        "[1,0,0,0,0,0,0,0,0,0],\n",
        "[1,0,1,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0,1,0],\n",
        "[0,0,0,0,0,0,1,0,0,0],\n",
        "[0,0,0,0,0,0,1,0,0,0],\n",
        "[0,0,1,0,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0,0,0],\n",
        "[1,0,0,0,0,0,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0,0,1],\n",
        "[0,0,0,0,0,0,0,0,0,0],\n",
        "[0,0,0,1,0,0,0,0,0,0]]"
      ],
      "metadata": {
        "id": "3nZFEoMdekvM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean_average_precision(jaccard_ranks))\n",
        "print(mean_reciprocal_rank(jaccard_ranks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8xRJNV4f2jG",
        "outputId": "dd745c9a-fa9b-446a-edcf-e22c415ab02d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3478306878306878\n",
            "0.35243386243386243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = 0\n",
        "for i in jaccard_ranks:\n",
        "  score +=ndcg_at_k(i,10)\n",
        "\n",
        "print(score/len(jaccard_ranks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSKxBz5Ff8vm",
        "outputId": "26833fb2-c6ba-4bc8-a177-e26c5900ece0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4468317488024309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = 0\n",
        "for i in jaccard_ranks:\n",
        "  score +=dcg_at_k(i,10)\n",
        "\n",
        "print(score/len(jaccard_ranks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBcl7-MKhDKr",
        "outputId": "36475a56-f320-4b3b-93f9-d840bca9b07b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.48496786440815515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bm25_ranks = [[1,0,0,1,0,0,0,0,1,1,0,1,0,0,0],\n",
        " [0,0,0,0,1,0,0,0,0,1,0,1,0,0,0],\n",
        " [0,0,0,1,1,0,0,0,1,0,1,0,0,0,0],\n",
        " [1,1,1,1,0,0,0,0,0,0,0,0,0,1,0],\n",
        " [0,0,0,0,0,0,0,0,1,0,0,0,0,0,0],\n",
        " [0,1,0,1,1,0,0,1,0,0,0,0,0,0,0],\n",
        " [1,0,0,1,0,0,0,0,1,0,0,0,0,1,0],\n",
        " [0,0,1,1,1,0,0,0,0,1,0,0,0,0,0],\n",
        " [1,0,0,0,0,0,1,0,0,1,0,0,0,1,0],\n",
        " [1,1,0,1,0,0,1,0,0,0,0,0,0,0,0],]"
      ],
      "metadata": {
        "id": "ESK0TQ8NhGNc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean_average_precision(bm25_ranks))\n",
        "print(mean_reciprocal_rank(bm25_ranks))\n",
        "score = 0\n",
        "for i in bm25_ranks:\n",
        "  score +=ndcg_at_k(i,15)\n",
        "print(score/len(bm25_ranks))\n",
        "\n",
        "score = 0\n",
        "for i in bm25_ranks:\n",
        "  score +=dcg_at_k(i,15)\n",
        "\n",
        "print(score/len(bm25_ranks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upqtWISUiPPx",
        "outputId": "589c9e34-a24f-4ae9-c778-8c67281b2f5f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.48772582972582973\n",
            "0.6394444444444445\n",
            "0.6322555461549959\n",
            "1.9631192259516435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QCH5qY0qibLV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}